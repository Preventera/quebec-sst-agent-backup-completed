# Agent AN1 - Analyste √âcarts SafetyAgentic
# ===========================================
# Analyse √©carts entre auto√©valuations (A1) et observations terrain (A2)
# pour identifier zones aveugles culture s√©curit√©

import asyncio
from typing import Dict, List, Tuple, Optional
import numpy as np
import logging
from datetime import datetime
import json

# Configuration logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SafetyAgentic.AN1")

class AN1AnalysteEcarts:
    """
    Agent AN1 - Analyste des √âcarts Culture S√©curit√©
    
    Fonctions principales:
    1. Analyser √©carts A1 (auto√©valuation) vs A2 (observation terrain)
    2. Identifier zones aveugles culture s√©curit√©
    3. Appliquer 12 mod√®les HSE simultan√©ment (HFACS, Swiss Cheese, etc.)
    4. Calculer scores de r√©alisme culturel
    5. G√©n√©rer recommandations cibl√©es
    """
    
    def __init__(self):
        """Initialisation Agent AN1"""
        self.agent_id = "AN1"
        self.agent_name = "Analyste √âcarts"
        self.version = "1.0.0"
        
        # Mod√®les HSE int√©gr√©s
        self.hse_models = {
            "hfacs_l1": "√âchecs organisationnels",
            "hfacs_l2": "Supervision inad√©quate", 
            "hfacs_l3": "Actes/conditions pr√©curseurs",
            "hfacs_l4": "Actes/conditions dangereux",
            "swiss_cheese": "D√©faillances barri√®res",
            "srk": "Niveaux comportement (Skill-Rule-Knowledge)",
            "reason": "Erreurs actives vs latentes",
            "bow_tie": "Analyse barri√®res pr√©ventives/protectives",
            "tripod": "Causes racines organisationnelles",
            "domino": "S√©quence causale incidents",
            "icam": "Investigation causale avanc√©e",
            "stamp": "Analyse syst√©mique complexe"
        }
        
        # Seuils d'√©carts critiques
        self.ecart_thresholds = {
            "faible": 10,      # √âcart < 10% = acceptable
            "modere": 25,      # √âcart 10-25% = √† surveiller
            "eleve": 50,       # √âcart 25-50% = critique
            "critique": 100    # √âcart > 50% = zone aveugle majeure
        }
        
        logger.info(f"ü§ñ Agent {self.agent_id} ({self.agent_name}) initialis√©")
    
    async def process(self, data_a1: Dict, data_a2: Dict, context: Dict = None) -> Dict:
        """
        Traitement principal: analyser √©carts A1 vs A2
        
        Args:
            data_a1: R√©sultats agent A1 (auto√©valuations)
            data_a2: R√©sultats agent A2 (observations terrain)
            context: Contexte incident/secteur/organisation
            
        Returns:
            Dict avec analyse compl√®te des √©carts
        """
        start_time = datetime.now()
        logger.info("üîÑ D√©marrage traitement Agent AN1")
        
        try:
            # 1. Validation donn√©es d'entr√©e
            self._validate_input_data(data_a1, data_a2)
            logger.info("‚úÖ Validation des donn√©es d'entr√©e r√©ussie")
            
            # 2. Calcul √©carts variables culture SST
            ecarts_variables = self._calculate_culture_gaps(data_a1, data_a2)
            
            # 3. Application des 12 mod√®les HSE
            analysis_hse = self._apply_hse_models(ecarts_variables, context)
            
            # 4. Identification zones aveugles
            zones_aveugles = self._identify_blind_spots(ecarts_variables)
            
            # 5. Calcul scores r√©alisme culturel
            realisme_scores = self._calculate_realism_scores(data_a1, data_a2)
            
            # 6. G√©n√©ration recommandations cibl√©es
            recommendations = self._generate_targeted_recommendations(
                ecarts_variables, zones_aveugles, analysis_hse
            )
            
            # 7. Calcul m√©triques performance
            performance_time = (datetime.now() - start_time).total_seconds()
            confidence_score = self._calculate_confidence_score(ecarts_variables)
            
            logger.info(f"üìä Performance AN1: {performance_time:.2f}s, confidence: {confidence_score:.2f}")
            
            # 8. Construction r√©sultat final
            result = {
                "agent_info": {
                    "agent_id": self.agent_id,
                    "agent_name": self.agent_name,
                    "version": self.version,
                    "timestamp": datetime.now().isoformat(),
                    "performance_time": performance_time,
                    "confidence_score": confidence_score
                },
                "ecarts_analysis": {
                    "ecarts_variables": ecarts_variables,
                    "zones_aveugles": zones_aveugles,
                    "realisme_scores": realisme_scores,
                    "nombre_ecarts_critiques": len([e for e in ecarts_variables.values() if e.get("niveau") == "critique"])
                },
                "hse_models_analysis": analysis_hse,
                "recommendations": recommendations,
                "summary": {
                    "ecart_moyen": np.mean([e.get("pourcentage", 0) for e in ecarts_variables.values()]),
                    "variables_critiques": len(zones_aveugles),
                    "actions_recommandees": len(recommendations),
                    "priorite_intervention": self._determine_intervention_priority(zones_aveugles)
                }
            }
            
            logger.info(f"‚úÖ Agent AN1 termin√© - Score confiance: {confidence_score:.2f}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur Agent AN1: {str(e)}")
            return {"error": str(e), "agent_id": self.agent_id}
    
    def _validate_input_data(self, data_a1: Dict, data_a2: Dict):
        """Validation des donn√©es A1 et A2"""
        if not data_a1 or not data_a2:
            raise ValueError("Donn√©es A1 ou A2 manquantes")
        
        # V√©rifier pr√©sence variables culture SST
        required_a1 = ["variables_culture_sst", "scores_autoeval"]
        required_a2 = ["variables_culture_terrain", "observations"]
        
        for field in required_a1:
            if field not in data_a1:
                raise ValueError(f"Champ manquant A1: {field}")
                
        for field in required_a2:
            if field not in data_a2:
                raise ValueError(f"Champ manquant A2: {field}")
    
    def _calculate_culture_gaps(self, data_a1: Dict, data_a2: Dict) -> Dict:
        """Calcul √©carts entre variables culture A1 vs A2"""
        ecarts = {}
        
        # Variables A1 (auto√©valuation)
        vars_a1 = data_a1.get("variables_culture_sst", {})
        vars_a2 = data_a2.get("variables_culture_terrain", {})
        
        # Analyser chaque variable commune
        for variable in set(vars_a1.keys()).intersection(set(vars_a2.keys())):
            score_a1 = vars_a1[variable].get("score", 0)
            score_a2 = vars_a2[variable].get("score", 0)
            
            # Calcul √©cart relatif
            if score_a1 > 0:
                ecart_pct = abs(score_a1 - score_a2) / score_a1 * 100
            else:
                ecart_pct = abs(score_a2) * 10  # P√©nalit√© si A1=0 mais A2>0
            
            # Classification niveau √©cart
            if ecart_pct < self.ecart_thresholds["faible"]:
                niveau = "faible"
            elif ecart_pct < self.ecart_thresholds["modere"]:
                niveau = "modere"
            elif ecart_pct < self.ecart_thresholds["eleve"]:
                niveau = "eleve"
            else:
                niveau = "critique"
            
            ecarts[variable] = {
                "score_autoeval": score_a1,
                "score_terrain": score_a2,
                "ecart_absolu": abs(score_a1 - score_a2),
                "pourcentage": ecart_pct,
                "niveau": niveau,
                "direction": "surestimation" if score_a1 > score_a2 else "sous_estimation",
                "variable_source_a1": vars_a1[variable].get("source", "unknown"),
                "variable_source_a2": vars_a2[variable].get("source", "unknown")
            }
        
        return ecarts
    
    def _apply_hse_models(self, ecarts_variables: Dict, context: Dict = None) -> Dict:
        """Application des 12 mod√®les HSE sur les √©carts"""
        hse_analysis = {}
        
        for model_code, model_name in self.hse_models.items():
            if model_code.startswith("hfacs"):
                analysis = self._apply_hfacs_model(model_code, ecarts_variables, context)
            elif model_code == "swiss_cheese":
                analysis = self._apply_swiss_cheese_model(ecarts_variables, context)
            elif model_code == "srk":
                analysis = self._apply_srk_model(ecarts_variables, context)
            elif model_code == "bow_tie":
                analysis = self._apply_bow_tie_model(ecarts_variables, context)
            else:
                # Analyse g√©n√©rique pour autres mod√®les
                analysis = self._apply_generic_hse_model(model_code, ecarts_variables, context)
            
            hse_analysis[model_code] = {
                "model_name": model_name,
                "analysis": analysis,
                "variables_impliquees": len([v for v in ecarts_variables.keys() if ecarts_variables[v]["niveau"] in ["eleve", "critique"]]),
                "score_applicabilite": self._calculate_model_applicability(model_code, ecarts_variables)
            }
        
        return hse_analysis
    
    def _apply_hfacs_model(self, level: str, ecarts: Dict, context: Dict) -> Dict:
        """Application mod√®le HFACS selon niveau"""
        hfacs_mapping = {
            "hfacs_l1": ["leadership_sst", "politique_securite", "ressources_securite"],
            "hfacs_l2": ["supervision_directe", "formation_superviseurs", "communication_risques"],
            "hfacs_l3": ["usage_epi", "respect_procedures", "maintenance_equipements"],
            "hfacs_l4": ["comportements_risque", "erreurs_execution", "violations_regles"]
        }
        
        variables_concernees = hfacs_mapping.get(level, [])
        ecarts_niveau = {v: ecarts[v] for v in variables_concernees if v in ecarts}
        
        return {
            "niveau_hfacs": level,
            "variables_analysees": len(ecarts_niveau),
            "ecarts_critiques": len([e for e in ecarts_niveau.values() if e["niveau"] == "critique"]),
            "score_defaillance": np.mean([e["pourcentage"] for e in ecarts_niveau.values()]) if ecarts_niveau else 0,
            "actions_recommandees": self._generate_hfacs_actions(level, ecarts_niveau)
        }
    
    def _apply_swiss_cheese_model(self, ecarts: Dict, context: Dict) -> Dict:
        """Application mod√®le Swiss Cheese - analyse d√©faillances barri√®res"""
        barrieres = {
            "barrieres_organisationnelles": ["politique_securite", "formation_securite", "audit_securite"],
            "barrieres_supervision": ["supervision_directe", "controle_epi", "inspection_equipements"],
            "barrieres_individuelles": ["competences_securite", "motivation_securite", "perception_risque"],
            "barrieres_techniques": ["equipements_protection", "systemes_alerte", "maintenance_preventive"]
        }
        
        defaillances = {}
        for barriere_type, variables in barrieres.items():
            ecarts_barriere = {v: ecarts[v] for v in variables if v in ecarts}
            defaillance_score = np.mean([e["pourcentage"] for e in ecarts_barriere.values()]) if ecarts_barriere else 0
            
            defaillances[barriere_type] = {
                "score_defaillance": defaillance_score,
                "variables_impliquees": list(ecarts_barriere.keys()),
                "niveau_risque": "high" if defaillance_score > 30 else "medium" if defaillance_score > 15 else "low"
            }
        
        return {
            "defaillances_barrieres": defaillances,
            "risque_global": max([d["score_defaillance"] for d in defaillances.values()]) if defaillances else 0,
            "barrieres_critiques": [k for k, v in defaillances.items() if v["niveau_risque"] == "high"]
        }
    
    def _apply_srk_model(self, ecarts: Dict, context: Dict) -> Dict:
        """Application mod√®le SRK (Skill-Rule-Knowledge)"""
        srk_mapping = {
            "skill": ["competences_techniques", "automatismes_securite", "reflexes_urgence"],
            "rule": ["respect_procedures", "application_consignes", "suivi_protocoles"],
            "knowledge": ["comprehension_risques", "analyse_situations", "prise_decision"]
        }
        
        srk_analysis = {}
        for niveau, variables in srk_mapping.items():
            ecarts_niveau = {v: ecarts[v] for v in variables if v in ecarts}
            score_ecart = np.mean([e["pourcentage"] for e in ecarts_niveau.values()]) if ecarts_niveau else 0
            
            srk_analysis[niveau] = {
                "score_ecart": score_ecart,
                "variables_count": len(ecarts_niveau),
                "defaillance_principale": max(ecarts_niveau.items(), key=lambda x: x[1]["pourcentage"])[0] if ecarts_niveau else None
            }
        
        return srk_analysis
    
    def _apply_bow_tie_model(self, ecarts: Dict, context: Dict) -> Dict:
        """Application mod√®le Bow-Tie - barri√®res pr√©ventives vs protectives"""
        return {
            "barrieres_preventives": {
                "formation": ecarts.get("formation_securite", {}).get("pourcentage", 0),
                "procedures": ecarts.get("respect_procedures", {}).get("pourcentage", 0),
                "supervision": ecarts.get("supervision_directe", {}).get("pourcentage", 0)
            },
            "barrieres_protectives": {
                "epi": ecarts.get("usage_epi", {}).get("pourcentage", 0),
                "systemes_urgence": ecarts.get("procedures_urgence", {}).get("pourcentage", 0),
                "premiers_secours": ecarts.get("formation_secours", {}).get("pourcentage", 0)
            }
        }
    
    def _apply_generic_hse_model(self, model_code: str, ecarts: Dict, context: Dict) -> Dict:
        """Analyse g√©n√©rique pour autres mod√®les HSE"""
        return {
            "model_code": model_code,
            "variables_analysees": len(ecarts),
            "score_global": np.mean([e["pourcentage"] for e in ecarts.values()]) if ecarts else 0,
            "applicable": True
        }
    
    def _identify_blind_spots(self, ecarts_variables: Dict) -> List[Dict]:
        """Identification zones aveugles culture s√©curit√©"""
        zones_aveugles = []
        
        for variable, ecart_data in ecarts_variables.items():
            if ecart_data["niveau"] in ["eleve", "critique"]:
                zone_aveugle = {
                    "variable": variable,
                    "type_ecart": ecart_data["direction"],
                    "pourcentage_ecart": ecart_data["pourcentage"],
                    "niveau_critique": ecart_data["niveau"],
                    "score_autoeval": ecart_data["score_autoeval"],
                    "score_terrain": ecart_data["score_terrain"],
                    "explication": self._explain_blind_spot(variable, ecart_data),
                    "impact_potentiel": self._assess_blind_spot_impact(variable, ecart_data)
                }
                zones_aveugles.append(zone_aveugle)
        
        # Trier par impact potentiel
        zones_aveugles.sort(key=lambda x: x["pourcentage_ecart"], reverse=True)
        return zones_aveugles
    
    def _explain_blind_spot(self, variable: str, ecart_data: Dict) -> str:
        """Explication textuelle de la zone aveugle"""
        direction = ecart_data["direction"]
        pct = ecart_data["pourcentage"]
        
        if direction == "surestimation":
            return f"Surestimation de {pct:.1f}% sur {variable}. L'√©quipe pense mieux performer qu'en r√©alit√©."
        else:
            return f"Sous-estimation de {pct:.1f}% sur {variable}. Performance terrain sup√©rieure aux perceptions."
    
    def _assess_blind_spot_impact(self, variable: str, ecart_data: Dict) -> str:
        """√âvaluation impact potentiel zone aveugle"""
        variable_criticality = {
            "usage_epi": "high",
            "respect_procedures": "high", 
            "supervision_directe": "high",
            "formation_securite": "medium",
            "communication_risques": "medium",
            "maintenance_equipements": "high"
        }
        
        criticality = variable_criticality.get(variable, "medium")
        ecart_level = ecart_data["niveau"]
        
        if criticality == "high" and ecart_level == "critique":
            return "CRITIQUE - Risque incident majeur"
        elif criticality == "high" or ecart_level == "critique":
            return "√âLEV√â - Intervention urgente requise"
        else:
            return "MOD√âR√â - Surveillance renforc√©e"
    
    def _calculate_realism_scores(self, data_a1: Dict, data_a2: Dict) -> Dict:
        """Calcul scores r√©alisme culturel"""
        scores_a1 = data_a1.get("scores_autoeval", {})
        observations_a2 = data_a2.get("observations", {})
        
        # Score r√©alisme global
        realisme_global = max(0, 100 - np.mean([
            abs(scores_a1.get("score_global", 50) - observations_a2.get("score_comportement", 50))
        ]))
        
        return {
            "realisme_global": realisme_global,
            "fiabilite_autoeval": min(100, realisme_global + 10),  # Bonus fiabilit√©
            "coherence_perception": realisme_global,
            "niveau_autocritique": "√©lev√©" if realisme_global > 80 else "moyen" if realisme_global > 60 else "faible"
        }
    
    def _generate_targeted_recommendations(self, ecarts: Dict, zones_aveugles: List, hse_analysis: Dict) -> List[Dict]:
        """G√©n√©ration recommandations cibl√©es"""
        recommendations = []
        
        # Recommandations par zone aveugle
        for zone in zones_aveugles[:5]:  # Top 5 priorit√©s
            rec = {
                "type": "zone_aveugle",
                "priorite": "URGENTE" if zone["niveau_critique"] == "critique" else "√âLEV√âE",
                "variable_cible": zone["variable"],
                "action": f"Corriger √©cart {zone['type_ecart']} de {zone['pourcentage_ecart']:.1f}% sur {zone['variable']}",
                "methode": self._recommend_correction_method(zone["variable"], zone["type_ecart"]),
                "timeline": "2-4 semaines" if zone["niveau_critique"] == "critique" else "1-2 mois",
                "ressources_requises": self._estimate_resources(zone["variable"], zone["pourcentage_ecart"])
            }
            recommendations.append(rec)
        
        # Recommandations HSE g√©n√©rales
        for model, analysis in hse_analysis.items():
            if analysis.get("score_applicabilite", 0) > 70:
                rec = {
                    "type": "hse_model",
                    "modele": model,
                    "priorite": "MOYENNE",
                    "action": f"Renforcer selon mod√®le {analysis['model_name']}",
                    "variables_impliquees": analysis.get("variables_impliquees", 0)
                }
                recommendations.append(rec)
        
        return recommendations
    
    def _recommend_correction_method(self, variable: str, direction: str) -> str:
        """Recommandation m√©thode correction selon variable et direction √©cart"""
        methods = {
            "usage_epi": {
                "surestimation": "Observations terrain cibl√©es + formations pratiques",
                "sous_estimation": "Sensibilisation performance + reconnaissance efforts"
            },
            "respect_procedures": {
                "surestimation": "Audit conformit√© + coaching superviseurs",
                "sous_estimation": "Communication succ√®s + valorisation bonnes pratiques"
            },
            "formation_securite": {
                "surestimation": "√âvaluation comp√©tences + formations compl√©mentaires",
                "sous_estimation": "Certification comp√©tences + reconnaissance expertise"
            }
        }
        
        return methods.get(variable, {}).get(direction, "Formation cibl√©e + suivi renforc√©")
    
    def _estimate_resources(self, variable: str, ecart_pct: float) -> str:
        """Estimation ressources requises pour correction"""
        if ecart_pct > 50:
            return "Ressources importantes - Formation compl√®te √©quipe"
        elif ecart_pct > 25:
            return "Ressources mod√©r√©es - Formation superviseurs + coaching"
        else:
            return "Ressources limit√©es - Sensibilisation cibl√©e"
    
    def _calculate_model_applicability(self, model_code: str, ecarts: Dict) -> float:
        """Calcul score applicabilit√© mod√®le selon √©carts"""
        # Score bas√© sur nombre variables concern√©es et niveau √©carts
        variables_critiques = len([e for e in ecarts.values() if e["niveau"] in ["eleve", "critique"]])
        total_variables = len(ecarts) if ecarts else 1
        
        return min(100, (variables_critiques / total_variables) * 100 + 20)
    
    def _calculate_confidence_score(self, ecarts_variables: Dict) -> float:
        """Calcul score confiance global analyse"""
        if not ecarts_variables:
            return 0.5
        
        # Score bas√© sur coh√©rence et nombre variables analys√©es
        coherence = np.mean([1 - (e["pourcentage"] / 100) for e in ecarts_variables.values()])
        completude = min(1.0, len(ecarts_variables) / 10)  # Optimal √† 10+ variables
        
        return max(0.3, min(0.95, (coherence * 0.7) + (completude * 0.3)))
    
    def _determine_intervention_priority(self, zones_aveugles: List) -> str:
        """D√©termination priorit√© intervention globale"""
        if not zones_aveugles:
            return "FAIBLE"
        
        critiques = len([z for z in zones_aveugles if z["niveau_critique"] == "critique"])
        eleves = len([z for z in zones_aveugles if z["niveau_critique"] == "eleve"])
        
        if critiques >= 3:
            return "URGENTE"
        elif critiques >= 1 or eleves >= 5:
            return "√âLEV√âE"
        elif eleves >= 2:
            return "MOYENNE"
        else:
            return "FAIBLE"
    
    def _generate_hfacs_actions(self, level: str, ecarts_niveau: Dict) -> List[str]:
        """G√©n√©ration actions HFACS selon niveau"""
        actions_map = {
            "hfacs_l1": [
                "R√©viser politique s√©curit√© organisationnelle",
                "Renforcer engagement leadership s√©curit√©",
                "Augmenter ressources d√©di√©es SST"
            ],
            "hfacs_l2": [
                "Former superviseurs √† l'encadrement s√©curit√©",
                "Structurer rondes s√©curit√© syst√©matiques",
                "Am√©liorer communication descendante risques"
            ],
            "hfacs_l3": [
                "Contr√¥ler application proc√©dures terrain",
                "V√©rifier port EPI syst√©matiquement",
                "Renforcer maintenance pr√©ventive"
            ],
            "hfacs_l4": [
                "Sensibiliser comportements √† risque",
                "Corriger erreurs d'ex√©cution r√©p√©t√©es",
                "Sanctionner violations d√©lib√©r√©es"
            ]
        }
        
        base_actions = actions_map.get(level, ["Action g√©n√©rique selon niveau"])
        
        # Personnaliser selon √©carts d√©tect√©s
        if ecarts_niveau:
            variable_critique = max(ecarts_niveau.items(), key=lambda x: x[1]["pourcentage"])[0]
            base_actions.append(f"Focus prioritaire sur: {variable_critique}")
        
        return base_actions[:3]  # Max 3 actions par niveau


# Test fonctionnel AN1
async def test_an1_analyste_ecarts():
    """Test fonctionnel Agent AN1 avec donn√©es simul√©es"""
    
    print("üß™ TEST AGENT AN1 - ANALYSTE √âCARTS")
    print("=" * 40)
    
    # Donn√©es simul√©es A1 (auto√©valuations)
    data_a1 = {
        "variables_culture_sst": {
            "usage_epi": {"score": 8.0, "source": "questionnaire"},
            "respect_procedures": {"score": 7.5, "source": "questionnaire"},
            "formation_securite": {"score": 6.8, "source": "questionnaire"},
            "supervision_directe": {"score": 7.2, "source": "questionnaire"},
            "communication_risques": {"score": 6.5, "source": "questionnaire"}
        },
        "scores_autoeval": {
            "score_global": 72,
            "fiabilite": 0.8
        }
    }
    
    # Donn√©es simul√©es A2 (observations terrain)
    data_a2 = {
        "variables_culture_terrain": {
            "usage_epi": {"score": 4.2, "source": "observation_epi"},
            "respect_procedures": {"score": 5.8, "source": "procedure_compliance"},
            "formation_securite": {"score": 6.9, "source": "behavioral_analysis"},
            "supervision_directe": {"score": 3.1, "source": "hazard_detection"},
            "communication_risques": {"score": 6.0, "source": "behavioral_analysis"}
        },
        "observations": {
            "score_comportement": 51,
            "dangers_detectes": 2
        }
    }
    
    # Contexte incident
    context = {
        "secteur": "CONSTRUCTION",
        "type_incident": "CHUTE",
        "gravite": "MAJEUR"
    }
    
    # Initialiser et tester AN1
    agent_an1 = AN1AnalysteEcarts()
    result = await agent_an1.process(data_a1, data_a2, context)
    
    # Affichage r√©sultats
    print("üìä R√âSULTATS AGENT AN1:")
    print("=" * 25)
    print(f"‚úÖ Score confiance: {result['agent_info']['confidence_score']:.3f}")
    print(f"üìä Variables analys√©es: {len(result['ecarts_analysis']['ecarts_variables'])}")
    print(f"‚ö†Ô∏è Zones aveugles d√©tect√©es: {result['ecarts_analysis']['nombre_ecarts_critiques']}")
    print(f"üéØ Mod√®les HSE appliqu√©s: {len(result['hse_models_analysis'])}")
    print(f"üí° Recommandations: {len(result['recommendations'])}")
    
    # Top √©carts d√©tect√©s
    print("\nüéØ TOP √âCARTS D√âTECT√âS:")
    for var, ecart in list(result['ecarts_analysis']['ecarts_variables'].items())[:3]:
        print(f"  - {var}: {ecart['pourcentage']:.1f}% ({ecart['niveau']}) - {ecart['direction']}")
    
    # Zones aveugles critiques
    print("\n‚ö†Ô∏è ZONES AVEUGLES CRITIQUES:")
    for zone in result['ecarts_analysis']['zones_aveugles'][:3]:
        print(f"  - {zone['variable']}: {zone['pourcentage_ecart']:.1f}% - {zone['impact_potentiel']}")
    
    # Analyse HSE
    print("\nüî¨ ANALYSE MOD√àLES HSE:")
    for model, analysis in list(result['hse_models_analysis'].items())[:3]:
        applicabilite = analysis.get('score_applicabilite', 0)
        print(f"  - {analysis['model_name']}: {applicabilite:.0f}% applicabilit√©")
    
    # Recommandations prioritaires
    print("\nüí° RECOMMANDATIONS PRIORITAIRES:")
    for rec in result['recommendations'][:3]:
        print(f"  - {rec['priorite']}: {rec['action']}")
        print(f"    ‚Üí M√©thode: {rec.get('methode', 'Non sp√©cifi√©e')}")
        print(f"    ‚Üí Timeline: {rec.get('timeline', 'Non sp√©cifi√©e')}")
    
    # Summary final
    print(f"\nüìã R√âSUM√â ANALYSE AN1:")
    print(f"  ‚Ä¢ √âcart moyen: {result['summary']['ecart_moyen']:.1f}%")
    print(f"  ‚Ä¢ Variables critiques: {result['summary']['variables_critiques']}")
    print(f"  ‚Ä¢ Actions recommand√©es: {result['summary']['actions_recommandees']}")
    print(f"  ‚Ä¢ Priorit√© intervention: {result['summary']['priorite_intervention']}")
    
    print(f"\n‚úÖ Test Agent AN1 termin√© avec succ√®s!")
    print(f"‚è±Ô∏è Performance: {result['agent_info']['performance_time']:.3f}s")
    return result

# Ex√©cution test si script appel√© directement
if __name__ == "__main__":
    import asyncio
    asyncio.run(test_an1_analyste_ecarts())